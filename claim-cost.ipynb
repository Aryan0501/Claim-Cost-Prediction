{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('InsNova_data_2023_train.csv/InsNova_data_2023_train.csv')\n",
    "data_vh= pd.read_csv('InsNova_data_2023_vh.csv/InsNova_data_2023_vh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>veh_value</th>\n",
       "      <th>exposure</th>\n",
       "      <th>veh_body</th>\n",
       "      <th>veh_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>area</th>\n",
       "      <th>agecat</th>\n",
       "      <th>engine_type</th>\n",
       "      <th>max_power</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>e_bill</th>\n",
       "      <th>time_of_week_driven</th>\n",
       "      <th>time_driven</th>\n",
       "      <th>trm_len</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>high_education_ind</th>\n",
       "      <th>clm</th>\n",
       "      <th>numclaims</th>\n",
       "      <th>claimcst0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.444504</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>weekday</td>\n",
       "      <td>6pm - 12am</td>\n",
       "      <td>6</td>\n",
       "      <td>640.448137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.45</td>\n",
       "      <td>0.562183</td>\n",
       "      <td>STNWG</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>weekday</td>\n",
       "      <td>6am - 12pm</td>\n",
       "      <td>12</td>\n",
       "      <td>683.749691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.465244</td>\n",
       "      <td>STNWG</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>petrol</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>weekday</td>\n",
       "      <td>6pm - 12am</td>\n",
       "      <td>6</td>\n",
       "      <td>653.656117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.271039</td>\n",
       "      <td>PANVN</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>petrol</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>weekday</td>\n",
       "      <td>12pm - 6pm</td>\n",
       "      <td>12</td>\n",
       "      <td>642.574671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.141624</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>petrol</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>weekday</td>\n",
       "      <td>6am - 12pm</td>\n",
       "      <td>6</td>\n",
       "      <td>647.175035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  veh_value  exposure veh_body  veh_age gender area  agecat engine_type  \\\n",
       "0   1       0.77  0.444504    SEDAN        4      M    D       3      petrol   \n",
       "1   2       4.45  0.562183    STNWG        1      M    A       3      petrol   \n",
       "2   3       4.90  0.465244    STNWG        1      F    A       3      petrol   \n",
       "3   4       0.48  0.271039    PANVN        4      M    A       4      petrol   \n",
       "4   5       0.85  0.141624    SEDAN        4      F    A       5      petrol   \n",
       "\n",
       "   max_power  ...  marital_status e_bill time_of_week_driven  time_driven  \\\n",
       "0        147  ...               S      1             weekday   6pm - 12am   \n",
       "1        158  ...               S      1             weekday   6am - 12pm   \n",
       "2        159  ...               M      1             weekday   6pm - 12am   \n",
       "3         80  ...               S      1             weekday   12pm - 6pm   \n",
       "4        126  ...               S      0             weekday   6am - 12pm   \n",
       "\n",
       "  trm_len credit_score  high_education_ind  clm  numclaims  claimcst0  \n",
       "0       6   640.448137                 1.0    0          0        0.0  \n",
       "1      12   683.749691                 0.0    0          0        0.0  \n",
       "2       6   653.656117                 1.0    0          0        0.0  \n",
       "3      12   642.574671                 0.0    0          0        0.0  \n",
       "4       6   647.175035                 0.0    0          0        0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07312436447234626"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.numclaims.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07847616168542991"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_claims=data['numclaims']\n",
    "np.array(num_claims).var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ryane\\anaconda3\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ryane\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\ryane\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Coefficient: 0.09828732592046496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\3248397478.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to calculate the Gini coefficient\n",
    "def gini(actual, pred):\n",
    "    assert(len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "    total_losses = all[:, 0].sum()\n",
    "    gini_sum = all[:, 0].cumsum().sum() / total_losses\n",
    "    gini_sum -= (len(actual) + 1) / 2.\n",
    "    return gini_sum / len(actual)\n",
    "\n",
    "# Load the training dataset\n",
    "file_path = 'InsNova_data_2023_train.csv/InsNova_data_2023_train.csv'  # Replace with your file path\n",
    "train_data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing: Encoding categorical variables and normalizing numerical variables\n",
    "train_data_encoded = pd.get_dummies(train_data, columns=['veh_body', 'gender', 'area', 'engine_type', 'time_of_week_driven', 'time_driven', 'marital_status'], drop_first=True)\n",
    "numerical_cols = ['veh_value', 'exposure', 'veh_age', 'agecat', 'max_power', 'driving_history_score', 'credit_score']\n",
    "scaler = StandardScaler()\n",
    "train_data_encoded[numerical_cols] = scaler.fit_transform(train_data_encoded[numerical_cols])\n",
    "\n",
    "# Defining features and target for predicting numclaims\n",
    "X = train_data_encoded.drop(['id', 'clm', 'numclaims', 'claimcst0', 'veh_color'], axis=1)  # Dropping non-feature columns\n",
    "y = train_data_encoded['numclaims']  # Target variable\n",
    "\n",
    "# Splitting the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculating the Gini coefficient\n",
    "gini_coefficient = gini(y_test, y_pred)\n",
    "print(\"Gini Coefficient:\", gini_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2985094121503573\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\3634245473.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\3634245473.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Gini Coefficient: 0.16139361165791366, RMSE: 0.290567057972532\n",
      "Poisson Regression - Gini Coefficient: 0.15236187008986135, RMSE: 0.29338620106308716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\3634245473.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Gini Coefficient: 0.10160424251176153, RMSE: 0.2990346241732971\n",
      "Gradient Boosting - Gini Coefficient: 0.14791946929334543, RMSE: 0.2919603685048672\n",
      "XGBoost - Gini Coefficient: 0.07016732156293462, RMSE: 0.30642331001899703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\3634245473.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\3634245473.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, PoissonRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to calculate the Gini coefficient\n",
    "def gini(actual, pred):\n",
    "    assert(len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "    total_losses = all[:, 0].sum()\n",
    "    gini_sum = all[:, 0].cumsum().sum() / total_losses\n",
    "    gini_sum -= (len(actual) + 1) / 2.\n",
    "    return gini_sum / len(actual)\n",
    "\n",
    "# Load the training dataset\n",
    "file_path = 'InsNova_data_2023_train.csv/InsNova_data_2023_train.csv'  # Replace with your file path\n",
    "train_data = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing\n",
    "train_data_encoded = pd.get_dummies(train_data, columns=['veh_body', 'gender', 'area', 'engine_type', 'time_of_week_driven', 'time_driven', 'marital_status'], drop_first=True)\n",
    "numerical_cols = ['veh_value', 'exposure', 'veh_age', 'agecat', 'max_power', 'driving_history_score', 'credit_score']\n",
    "scaler = StandardScaler()\n",
    "train_data_encoded[numerical_cols] = scaler.fit_transform(train_data_encoded[numerical_cols])\n",
    "\n",
    "# Defining features and target\n",
    "X = train_data_encoded.drop(['id', 'clm', 'numclaims', 'claimcst0', 'veh_color'], axis=1)\n",
    "y = train_data_encoded['numclaims']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Poisson Regression\": PoissonRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": xgb.XGBRegressor()\n",
    "}\n",
    "\n",
    "# Training and evaluating models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    gini_coeff = gini(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"{name} - Gini Coefficient: {gini_coeff}, RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=3)\n",
    "\n",
    "# Fit to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\3634245473.py:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Model - Gini Coefficient: 0.1592078795294881\n",
      "Optimal Model - RMSE: 0.2914194710111743\n",
      "Cross-Validation - Mean MSE: -0.07538518232808807 Std Dev: 0.0025057817254967307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Retraining the model with the best parameters\n",
    "optimal_model = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0)\n",
    "optimal_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_optimal = optimal_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "gini_coefficient_optimal = gini(y_test, y_pred_optimal)\n",
    "rmse_optimal = np.sqrt(mean_squared_error(y_test, y_pred_optimal))\n",
    "print(\"Optimal Model - Gini Coefficient:\", gini_coefficient_optimal)\n",
    "print(\"Optimal Model - RMSE:\", rmse_optimal)\n",
    "\n",
    "# Cross-Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(optimal_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# The mean score and the 95% confidence interval of the score estimate\n",
    "mean_cv_score = np.mean(cv_scores)\n",
    "std_cv_score = np.std(cv_scores)\n",
    "print(\"Cross-Validation - Mean MSE:\", mean_cv_score, \"Std Dev:\", std_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         22620.000000\n",
       "Predict        1.157499\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the validation dataset\n",
    "validation_data_path = 'InsNova_data_2023_vh.csv/InsNova_data_2023_vh.csv'\n",
    "validation_data = pd.read_csv(validation_data_path)\n",
    "\n",
    "# Preprocessing the validation data similar to the training data\n",
    "validation_data_encoded = pd.get_dummies(validation_data, columns=['veh_body', 'gender', 'area', 'engine_type', 'time_of_week_driven', 'time_driven', 'marital_status'], drop_first=True)\n",
    "validation_data_encoded[numerical_cols] = scaler.transform(validation_data_encoded[numerical_cols])\n",
    "\n",
    "# Ensure the same columns in validation data as in training data\n",
    "validation_data_encoded = validation_data_encoded.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Predicting on the validation dataset\n",
    "validation_predictions = optimal_model.predict(validation_data_encoded)\n",
    "\n",
    "# Creating a DataFrame for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': validation_data['id'],\n",
    "    'Predict': validation_predictions\n",
    "})\n",
    "\n",
    "# Checking the first few rows of the submission file\n",
    "submission_df.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0851712  1.02389089 1.0715956  1.08637129 1.02985773 1.0342072\n",
      " 1.07341546 1.04825894 1.0259283  1.13714216 1.21276976 1.02216809\n",
      " 1.02547954 1.1105667  1.15675799 1.17829313 1.08466942 1.0246307\n",
      " 1.04011292 1.09623875 1.02651615 1.06601708 1.02731963 1.27480207\n",
      " 1.03130111 1.02765691 1.07090419 1.04478271 1.02536096 1.09297915\n",
      " 1.07363894 1.01895365 1.02623881 1.23257165 1.0090989  1.13993042\n",
      " 1.17482325 1.17679507 1.00709813 1.0505753  1.062162   1.09881837\n",
      " 1.08784966 1.72370977 1.12581923 1.06071094 1.03782956 1.13440398\n",
      " 1.19000083 1.1479211  1.23164721 1.06710672 1.01819194 1.02592467\n",
      " 1.03292433 1.0346937  1.02772265 1.03319592 1.03465041 1.0261923\n",
      " 1.01895048 1.09246272 1.02879199 1.07332932 1.01766794 1.31675933\n",
      " 1.0713949  1.13006875 1.15618688 1.08408576 1.02144095 1.09302293\n",
      " 1.12067045 1.02360102 1.06769625 1.10289663 1.09713601 1.08595291\n",
      " 1.11500659 1.14251035 1.08884746 1.04582977 1.02798298 1.13484575\n",
      " 1.183595   1.02724615 1.13162957 1.01580575 1.13023511 1.02425392\n",
      " 1.07305848 1.07034396 1.03005971 1.01570447 1.09953783 1.03395059\n",
      " 1.06563802 1.19670522 1.11356406 1.08576937 1.28324036 1.04615457\n",
      " 1.08179993 1.02977452 1.0324117  1.19387563 1.07559398 1.05434254\n",
      " 1.02489216 1.12635575 1.05290127 1.1208023  1.10637306 1.02799931\n",
      " 1.0572353  1.04808761 1.26545498 1.02150293 1.02440663 1.24695307\n",
      " 1.07103375 1.17360671 1.02681523 1.01688097 1.01992262 1.08516045\n",
      " 1.19435935 1.01518581 1.02210461 1.06714449 1.17387637 1.04904719\n",
      " 1.11185509 1.14754636 1.04854667 1.07875121 1.06979902 1.05514771\n",
      " 1.08627447 1.16463356 1.03094544 1.04678044 1.16530871 1.01970582\n",
      " 1.16014655 1.01693412 1.11011308 1.02364821 1.03936116 1.07311288\n",
      " 1.02804446 1.02434753 1.15735101 1.03455163 1.07248095 1.03527372\n",
      " 1.1302124  1.14979872 1.05513266 1.01955065 1.05410475 1.04726871\n",
      " 1.06697446 1.20254443 1.0254088  1.02405524 1.02043471 1.01978245\n",
      " 1.06008026 1.02625725 1.0451262  1.02058727 1.14820496 1.06146879\n",
      " 1.07470745 1.10748877 1.23659821 1.02446996 1.13459333 1.10232146\n",
      " 1.12099811 1.09147233 1.02499497 1.10241993 1.01292531 1.11441204\n",
      " 1.03267071 1.07855199 1.03134988 1.01770957 1.02735164 1.02463514\n",
      " 1.07356777 1.01891142 1.20367246 1.08500162 1.12513988 1.05006854\n",
      " 1.02184199 1.04908666 1.07352823 1.0157235  1.02029998 1.11152204\n",
      " 1.11419903 1.01908475 1.08617389 1.01452704 1.15496344 1.07819259\n",
      " 1.08831138 1.0357541  1.07212647 1.020072   1.02466513 1.0966534\n",
      " 1.08895684 1.1313805  1.0505824  1.1176478  1.04729226 1.10922055\n",
      " 1.0677258  1.10242522 1.0231722  1.06193847 1.10126893 1.18340207\n",
      " 1.097231   1.28660515 1.08623248 1.0976788  1.09335187 1.13851909\n",
      " 1.06987743 1.1769412  1.02842366 1.08426117 1.02168166 1.16681338\n",
      " 1.05308937 1.09617814 1.0833352  1.08271151 1.06085336 1.07455232\n",
      " 1.09207734 1.05373201 1.02248666 1.08957346 1.17265655 1.06087784\n",
      " 1.047342   1.14310804 1.18558323 1.02116423 1.13458636 1.0717254\n",
      " 1.22088304 1.05949275 1.08312395 1.02265676 1.02201761 1.02099581\n",
      " 1.16625027 1.09944148 1.12025541 1.13726481 1.2095005  1.02167656\n",
      " 1.07361369 1.03143034 1.07418553 1.13456201 1.03208262 1.0265266\n",
      " 1.03143518 1.10149525 1.11212656 1.03092786 1.01141477 1.10603458\n",
      " 1.02318952 1.04122896 1.02184777 1.12756053 1.02767656 1.09538571\n",
      " 1.10947326 1.05468669 1.01426007 1.09124551 1.05288448 1.06219256\n",
      " 1.10662896 1.04064252 1.11470888 1.02586834 1.09237083 1.02290203\n",
      " 1.06853924 1.03328852 1.01914834 1.09103556 1.03471307 1.02309815\n",
      " 1.08778728 1.08990345 1.09039578 1.02273246 1.02357382 1.03009044\n",
      " 1.05755958]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'InsNova_data_2023_train.csv/InsNova_data_2023_train.csv'  # Update the path accordingly\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Separating the target variable and features\n",
    "X = data.drop('numclaims', axis=1)\n",
    "y = data['numclaims']\n",
    "\n",
    "# Identifying numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Creating transformers for numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundling preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Splitting the dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Function to train a model and get predictions\n",
    "def train_and_predict(model, X_train, y_train, X_test):\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    return predictions\n",
    "\n",
    "# Training and predicting with each model\n",
    "lr_predictions = train_and_predict(LinearRegression(), X_train, y_train, X_test)\n",
    "rf_predictions = train_and_predict(RandomForestRegressor(random_state=0), X_train, y_train, X_test)\n",
    "gb_predictions = train_and_predict(GradientBoostingRegressor(random_state=0), X_train, y_train, X_test)\n",
    "\n",
    "# Calculating MSE for each model\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
    "\n",
    "# Calculating weights inversely proportional to the MSE\n",
    "total_inverse_mse = (1 / lr_mse) + (1 / rf_mse) + (1 / gb_mse)\n",
    "lr_weight = (1 / lr_mse) / total_inverse_mse\n",
    "rf_weight = (1 / rf_mse) / total_inverse_mse\n",
    "gb_weight = (1 / gb_mse) / total_inverse_mse\n",
    "\n",
    "# Combining predictions using weighted average\n",
    "combined_predictions = (lr_weight * lr_predictions) + (rf_weight * rf_predictions) + (gb_weight * gb_predictions)\n",
    "\n",
    "# Displaying combined predictions\n",
    "print(combined_predictions[combined_predictions>1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0851712  1.02389089 1.0715956  1.08637129 1.02985773 1.0342072\n",
      " 1.07341546 1.04825894 1.0259283  1.13714216 1.21276976 1.02216809\n",
      " 1.02547954 1.1105667  1.15675799 1.17829313 1.08466942 1.0246307\n",
      " 1.04011292 1.09623875 1.02651615 1.06601708 1.02731963 1.27480207\n",
      " 1.03130111 1.02765691 1.07090419 1.04478271 1.02536096 1.09297915\n",
      " 1.07363894 1.01895365 1.02623881 1.23257165 1.0090989  1.13993042\n",
      " 1.17482325 1.17679507 1.00709813 1.0505753  1.062162   1.09881837\n",
      " 1.08784966 1.72370977 1.12581923 1.06071094 1.03782956 1.13440398\n",
      " 1.19000083 1.1479211  1.23164721 1.06710672 1.01819194 1.02592467\n",
      " 1.03292433 1.0346937  1.02772265 1.03319592 1.03465041 1.0261923\n",
      " 1.01895048 1.09246272 1.02879199 1.07332932 1.01766794 1.31675933\n",
      " 1.0713949  1.13006875 1.15618688 1.08408576 1.02144095 1.09302293\n",
      " 1.12067045 1.02360102 1.06769625 1.10289663 1.09713601 1.08595291\n",
      " 1.11500659 1.14251035 1.08884746 1.04582977 1.02798298 1.13484575\n",
      " 1.183595   1.02724615 1.13162957 1.01580575 1.13023511 1.02425392\n",
      " 1.07305848 1.07034396 1.03005971 1.01570447 1.09953783 1.03395059\n",
      " 1.06563802 1.19670522 1.11356406 1.08576937 1.28324036 1.04615457\n",
      " 1.08179993 1.02977452 1.0324117  1.19387563 1.07559398 1.05434254\n",
      " 1.02489216 1.12635575 1.05290127 1.1208023  1.10637306 1.02799931\n",
      " 1.0572353  1.04808761 1.26545498 1.02150293 1.02440663 1.24695307\n",
      " 1.07103375 1.17360671 1.02681523 1.01688097 1.01992262 1.08516045\n",
      " 1.19435935 1.01518581 1.02210461 1.06714449 1.17387637 1.04904719\n",
      " 1.11185509 1.14754636 1.04854667 1.07875121 1.06979902 1.05514771\n",
      " 1.08627447 1.16463356 1.03094544 1.04678044 1.16530871 1.01970582\n",
      " 1.16014655 1.01693412 1.11011308 1.02364821 1.03936116 1.07311288\n",
      " 1.02804446 1.02434753 1.15735101 1.03455163 1.07248095 1.03527372\n",
      " 1.1302124  1.14979872 1.05513266 1.01955065 1.05410475 1.04726871\n",
      " 1.06697446 1.20254443 1.0254088  1.02405524 1.02043471 1.01978245\n",
      " 1.06008026 1.02625725 1.0451262  1.02058727 1.14820496 1.06146879\n",
      " 1.07470745 1.10748877 1.23659821 1.02446996 1.13459333 1.10232146\n",
      " 1.12099811 1.09147233 1.02499497 1.10241993 1.01292531 1.11441204\n",
      " 1.03267071 1.07855199 1.03134988 1.01770957 1.02735164 1.02463514\n",
      " 1.07356777 1.01891142 1.20367246 1.08500162 1.12513988 1.05006854\n",
      " 1.02184199 1.04908666 1.07352823 1.0157235  1.02029998 1.11152204\n",
      " 1.11419903 1.01908475 1.08617389 1.01452704 1.15496344 1.07819259\n",
      " 1.08831138 1.0357541  1.07212647 1.020072   1.02466513 1.0966534\n",
      " 1.08895684 1.1313805  1.0505824  1.1176478  1.04729226 1.10922055\n",
      " 1.0677258  1.10242522 1.0231722  1.06193847 1.10126893 1.18340207\n",
      " 1.097231   1.28660515 1.08623248 1.0976788  1.09335187 1.13851909\n",
      " 1.06987743 1.1769412  1.02842366 1.08426117 1.02168166 1.16681338\n",
      " 1.05308937 1.09617814 1.0833352  1.08271151 1.06085336 1.07455232\n",
      " 1.09207734 1.05373201 1.02248666 1.08957346 1.17265655 1.06087784\n",
      " 1.047342   1.14310804 1.18558323 1.02116423 1.13458636 1.0717254\n",
      " 1.22088304 1.05949275 1.08312395 1.02265676 1.02201761 1.02099581\n",
      " 1.16625027 1.09944148 1.12025541 1.13726481 1.2095005  1.02167656\n",
      " 1.07361369 1.03143034 1.07418553 1.13456201 1.03208262 1.0265266\n",
      " 1.03143518 1.10149525 1.11212656 1.03092786 1.01141477 1.10603458\n",
      " 1.02318952 1.04122896 1.02184777 1.12756053 1.02767656 1.09538571\n",
      " 1.10947326 1.05468669 1.01426007 1.09124551 1.05288448 1.06219256\n",
      " 1.10662896 1.04064252 1.11470888 1.02586834 1.09237083 1.02290203\n",
      " 1.06853924 1.03328852 1.01914834 1.09103556 1.03471307 1.02309815\n",
      " 1.08778728 1.08990345 1.09039578 1.02273246 1.02357382 1.03009044\n",
      " 1.05755958]\n"
     ]
    }
   ],
   "source": [
    "print(combined_predictions[combined_predictions>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the training dataset\n",
    "file_path_train = 'InsNova_data_2023_train.csv/InsNova_data_2023_train.csv'  # Update with your file path\n",
    "data_train = pd.read_csv(file_path_train)\n",
    "\n",
    "# Separating the target variable and features for the training dataset\n",
    "X_train_full = data_train.drop('numclaims', axis=1)\n",
    "y_train_full = data_train['numclaims']\n",
    "\n",
    "# Identifying numerical and categorical columns from the training data\n",
    "numerical_cols = X_train_full.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train_full.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Creating transformers for numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundling preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Splitting the training dataset (optional if you want to evaluate models on the training data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=0)\n",
    "\n",
    "# Load the validation dataset\n",
    "file_path_vh = 'InsNova_data_2023_vh.csv/InsNova_data_2023_vh.csv'  # Update with your file path\n",
    "data_vh = pd.read_csv(file_path_vh)\n",
    "\n",
    "# Adjusting the preprocessing to only include common columns\n",
    "numerical_cols_common = [col for col in numerical_cols if col in data_vh.columns]\n",
    "categorical_cols_common = [col for col in categorical_cols if col in data_vh.columns]\n",
    "\n",
    "# Updated preprocessor for the validation dataset\n",
    "preprocessor_common = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols_common),\n",
    "        ('cat', categorical_transformer, categorical_cols_common)\n",
    "    ])\n",
    "\n",
    "# Function to train a model on the training set and predict on a given dataset\n",
    "def train_and_predict_common(model, X_train, y_train, X_predict):\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor_common),\n",
    "                               ('model', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    predictions = pipeline.predict(X_predict)\n",
    "    return predictions\n",
    "\n",
    "# Training models and predicting on the validation dataset\n",
    "lr_predictions_vh = train_and_predict_common(LinearRegression(), X_train_full, y_train_full, data_vh)\n",
    "rf_predictions_vh = train_and_predict_common(RandomForestRegressor(random_state=0), X_train_full, y_train_full, data_vh)\n",
    "gb_predictions_vh = train_and_predict_common(GradientBoostingRegressor(random_state=0), X_train_full, y_train_full, data_vh)\n",
    "\n",
    "# Combining predictions using weighted average\n",
    "# First, compute weights based on MSE of each model on the training split (if you did this step)\n",
    "# If not, you can assign equal weights or based on model confidence\n",
    "# Example with equal weights: (You can modify this part based on your model evaluation)\n",
    "weights = [1/3, 1/3, 1/3]  # Equal weights for LR, RF, GB\n",
    "combined_predictions_vh = (weights[0] * lr_predictions_vh) + (weights[1] * rf_predictions_vh) + (weights[2] * gb_predictions_vh)\n",
    "\n",
    "# Adding the combined predictions as a new column in the validation dataset\n",
    "data_vh['num_claim'] = combined_predictions_vh\n",
    "\n",
    "# Save the updated validation dataset with predictions\n",
    "output_path = 'numberofclaims.csv'  # Update with your file path\n",
    "data_vh.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_vh[data_vh['num_claim']>0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\2532396906.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_12764\\2532396906.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Function to calculate the Gini index for regression\n",
    "def gini(actual, pred):\n",
    "    assert(len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1*all[:, 1]))]\n",
    "    total_losses = all[:, 0].sum()\n",
    "    gini_sum = all[:, 0].cumsum().sum() / total_losses\n",
    "    gini_sum -= (len(actual) + 1) / 2.0\n",
    "    return gini_sum / len(actual)\n",
    "\n",
    "def normalized_gini(actual, pred):\n",
    "    return gini(actual, pred) / gini(actual, actual)\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('InsNova_data_2023_train.csv/InsNova_data_2023_train.csv')\n",
    "vh_data = pd.read_csv('InsNova_data_2023_vh.csv/InsNova_data_2023_vh.csv')\n",
    "\n",
    "# Preprocessing steps\n",
    "categorical_cols = train_data.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = train_data.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_cols = numerical_cols.drop(['clm', 'numclaims', 'claimcst0'])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    train_data.drop(['clm', 'numclaims', 'claimcst0'], axis=1), \n",
    "    train_data['claimcst0'], \n",
    "    test_size=0.2, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_estimators=100, random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(n_estimators=100, random_state=0),\n",
    "    #\"LinearRegression\": LinearRegression()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    valid_preds = pipeline.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, valid_preds)\n",
    "    gini_score = normalized_gini(y_valid, valid_preds)\n",
    "    results[model_name] = {'MSE': mse, 'Gini': gini_score}\n",
    "\n",
    "# Select the best model\n",
    "best_model_name = min(results, key=lambda k: (results[k]['MSE'], -results[k]['Gini']))\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "# Train best model on the entire training set\n",
    "best_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "best_pipeline.fit(train_data.drop(['clm', 'numclaims', 'claimcst0'], axis=1), train_data['claimcst0'])\n",
    "\n",
    "# Predict with the best model\n",
    "vh_preds_best = best_pipeline.predict(vh_data)\n",
    "\n",
    "# Prepare output\n",
    "output_best = pd.DataFrame({'id': vh_data['id'], 'Predict': vh_preds_best})\n",
    "\n",
    "# Save output to CSV\n",
    "output_best.to_csv('predictions_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of numclaims: 0.07312436447234626\n",
      "Variance of numclaims: 0.0784796313185289\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:              numclaims   No. Observations:                22619\n",
      "Model:                            GLM   Df Residuals:                    22605\n",
      "Model Family:                Gaussian   Df Model:                           13\n",
      "Link Function:               identity   Scale:                        0.077320\n",
      "Method:                          IRLS   Log-Likelihood:                -3137.9\n",
      "Date:                Thu, 16 Nov 2023   Deviance:                       1747.8\n",
      "Time:                        05:05:25   Pearson chi2:                 1.75e+03\n",
      "No. Iterations:                     3   Pseudo R-squ. (CS):            0.01545\n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.0985      0.116      0.852      0.394      -0.128       0.325\n",
      "area[T.B]                -0.0026      0.006     -0.461      0.645      -0.014       0.008\n",
      "area[T.C]                -0.0002      0.005     -0.042      0.967      -0.010       0.010\n",
      "area[T.D]                -0.0109      0.007     -1.648      0.099      -0.024       0.002\n",
      "area[T.E]                -0.0105      0.007     -1.422      0.155      -0.025       0.004\n",
      "area[T.F]                 0.0035      0.009      0.388      0.698      -0.014       0.021\n",
      "gender[T.M]              -0.0057      0.004     -1.488      0.137      -0.013       0.002\n",
      "exposure                  0.1215      0.007     17.838      0.000       0.108       0.135\n",
      "agecat                   -0.0063      0.001     -4.796      0.000      -0.009      -0.004\n",
      "veh_value                 0.0006      0.002      0.323      0.746      -0.003       0.004\n",
      "veh_age                   0.0007      0.002      0.322      0.747      -0.003       0.005\n",
      "driving_history_score     0.0001   9.69e-05      1.303      0.192   -6.36e-05       0.000\n",
      "max_power              3.028e-06   3.76e-05      0.081      0.936   -7.06e-05    7.67e-05\n",
      "credit_score          -9.746e-05      0.000     -0.552      0.581      -0.000       0.000\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('InsNova_data_2023_train.csv/InsNova_data_2023_train.csv')\n",
    "\n",
    "# Check mean and variance of numclaims\n",
    "mean_numclaims = train_data['numclaims'].mean()\n",
    "var_numclaims = train_data['numclaims'].var()\n",
    "\n",
    "print(f\"Mean of numclaims: {mean_numclaims}\")\n",
    "print(f\"Variance of numclaims: {var_numclaims}\")\n",
    "\n",
    "# Poisson regression model for Frequency\n",
    "#formula = 'numclaims ~ np.log(exposure) + agecat + area + veh_value + veh_age + veh_value:veh_age + area:veh_value'\n",
    "#frequency_model = glm(formula, data=train_data, family=sm.families.Poisson()).fit()\n",
    "\n",
    "formula = 'numclaims ~  exposure + agecat + area + veh_value + veh_age + gender + driving_history_score  + max_power + credit_score '\n",
    "frequency_model = glm(formula, data=train_data).fit()\n",
    "\n",
    "print(frequency_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>veh_value</th>\n",
       "      <th>exposure</th>\n",
       "      <th>veh_age</th>\n",
       "      <th>agecat</th>\n",
       "      <th>max_power</th>\n",
       "      <th>driving_history_score</th>\n",
       "      <th>e_bill</th>\n",
       "      <th>trm_len</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>high_education_ind</th>\n",
       "      <th>clm</th>\n",
       "      <th>numclaims</th>\n",
       "      <th>claimcst0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.00000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "      <td>22619.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11310.000000</td>\n",
       "      <td>1.868948</td>\n",
       "      <td>0.433038</td>\n",
       "      <td>2.667492</td>\n",
       "      <td>3.481675</td>\n",
       "      <td>152.447765</td>\n",
       "      <td>70.868341</td>\n",
       "      <td>0.63681</td>\n",
       "      <td>10.493833</td>\n",
       "      <td>649.875077</td>\n",
       "      <td>0.117114</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>0.073124</td>\n",
       "      <td>163.048084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6529.687205</td>\n",
       "      <td>1.278588</td>\n",
       "      <td>0.272899</td>\n",
       "      <td>1.070555</td>\n",
       "      <td>1.420252</td>\n",
       "      <td>51.834156</td>\n",
       "      <td>19.083318</td>\n",
       "      <td>0.48093</td>\n",
       "      <td>2.601685</td>\n",
       "      <td>10.515364</td>\n",
       "      <td>0.321563</td>\n",
       "      <td>0.252048</td>\n",
       "      <td>0.280142</td>\n",
       "      <td>1271.955238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>607.797435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5655.500000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>0.203696</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>643.134748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11310.000000</td>\n",
       "      <td>1.570000</td>\n",
       "      <td>0.384313</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>647.180197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16964.500000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0.643316</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>654.069205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22619.000000</td>\n",
       "      <td>24.510000</td>\n",
       "      <td>0.999378</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>790.360253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>57895.584560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     veh_value      exposure       veh_age        agecat  \\\n",
       "count  22619.000000  22619.000000  22619.000000  22619.000000  22619.000000   \n",
       "mean   11310.000000      1.868948      0.433038      2.667492      3.481675   \n",
       "std     6529.687205      1.278588      0.272899      1.070555      1.420252   \n",
       "min        1.000000      0.000000      0.001754      1.000000      1.000000   \n",
       "25%     5655.500000      1.070000      0.203696      2.000000      2.000000   \n",
       "50%    11310.000000      1.570000      0.384313      3.000000      3.000000   \n",
       "75%    16964.500000      2.260000      0.643316      4.000000      5.000000   \n",
       "max    22619.000000     24.510000      0.999378      4.000000      6.000000   \n",
       "\n",
       "          max_power  driving_history_score       e_bill       trm_len  \\\n",
       "count  22619.000000           22619.000000  22619.00000  22619.000000   \n",
       "mean     152.447765              70.868341      0.63681     10.493833   \n",
       "std       51.834156              19.083318      0.48093      2.601685   \n",
       "min       60.000000               1.000000      0.00000      6.000000   \n",
       "25%      115.000000              58.000000      0.00000      6.000000   \n",
       "50%      144.000000              72.000000      1.00000     12.000000   \n",
       "75%      180.000000              86.000000      1.00000     12.000000   \n",
       "max      409.000000              99.000000      1.00000     12.000000   \n",
       "\n",
       "       credit_score  high_education_ind           clm     numclaims  \\\n",
       "count  22619.000000        22619.000000  22619.000000  22619.000000   \n",
       "mean     649.875077            0.117114      0.068173      0.073124   \n",
       "std       10.515364            0.321563      0.252048      0.280142   \n",
       "min      607.797435            0.000000      0.000000      0.000000   \n",
       "25%      643.134748            0.000000      0.000000      0.000000   \n",
       "50%      647.180197            0.000000      0.000000      0.000000   \n",
       "75%      654.069205            0.000000      0.000000      0.000000   \n",
       "max      790.360253            1.000000      1.000000      3.000000   \n",
       "\n",
       "          claimcst0  \n",
       "count  22619.000000  \n",
       "mean     163.048084  \n",
       "std     1271.955238  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max    57895.584560  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:         avg_claim_cost   No. Observations:                 1542\n",
      "Model:                            GLM   Df Residuals:                     1533\n",
      "Model Family:                Gaussian   Df Model:                            8\n",
      "Link Function:               identity   Scale:                      1.7236e+07\n",
      "Method:                          IRLS   Log-Likelihood:                -15030.\n",
      "Date:                Thu, 16 Nov 2023   Deviance:                   2.6423e+10\n",
      "Time:                        05:05:27   Pearson chi2:                 2.64e+10\n",
      "No. Iterations:                     3   Pseudo R-squ. (CS):            0.01544\n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept              5192.6613   6203.137      0.837      0.403   -6965.263    1.74e+04\n",
      "gender[T.M]             565.5564    221.158      2.557      0.011     132.095     999.018\n",
      "veh_age                  82.0190    123.620      0.663      0.507    -160.272     324.310\n",
      "agecat                  -89.5907     75.179     -1.192      0.233    -236.940      57.758\n",
      "max_power                 2.2197      2.168      1.024      0.306      -2.029       6.469\n",
      "veh_value                16.8582    111.657      0.151      0.880    -201.986     235.702\n",
      "driving_history_score     9.4548      5.625      1.681      0.093      -1.571      20.480\n",
      "exposure              -1314.5573    405.509     -3.242      0.001   -2109.340    -519.775\n",
      "credit_score             -5.2443      9.467     -0.554      0.580     -23.800      13.311\n",
      "=========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse Gaussian model for Severity\n",
    "# Create a new column for the average claim cost\n",
    "train_data_with_claims['avg_claim_cost'] = train_data_with_claims['claimcst0'] / train_data_with_claims['numclaims']\n",
    "\n",
    "# Inverse Gaussian model for Severity\n",
    "#severity_model = glm('avg_claim_cost ~ gender + veh_age + agecat', \n",
    " #                    data=train_data_with_claims, \n",
    "  #                   family=sm.families.InverseGaussian(link=sm.families.links.log())).fit()\n",
    "\n",
    "severity_model = glm('avg_claim_cost ~ gender + veh_age + agecat + max_power + veh_value + driving_history_score + exposure + credit_score', \n",
    "                     data=train_data_with_claims).fit()\n",
    "\n",
    "print(severity_model.summary())\n",
    "\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Gini Coefficient from Cross-Validation: 0.2860533099866334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1342160008.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "def gini(actual, pred):\n",
    "    assert len(actual) == len(pred)\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "    total_losses = all[:, 0].sum()\n",
    "    gini_sum = all[:, 0].cumsum().sum() / total_losses\n",
    "    gini_sum -= (len(actual) + 1) / 2.\n",
    "    return gini_sum / len(actual)\n",
    "\n",
    "def normalized_gini(actual, pred):\n",
    "    return gini(actual, pred) / gini(actual, actual)\n",
    "\n",
    "# Prepare for cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "gini_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(train_data):\n",
    "    cv_train, cv_test = train_data.iloc[train_index], train_data.iloc[test_index]\n",
    "    \n",
    "    # Fit the model on cv_train\n",
    "    #cv_model = glm(formula, data=cv_train, family=sm.families.Poisson()).fit()\n",
    "    cv_model = glm(formula, data=cv_train).fit()\n",
    "    # Predict on cv_test\n",
    "    predictions = cv_model.predict(cv_test)\n",
    "    \n",
    "    # Compute and store Gini coefficient\n",
    "    gini_score = normalized_gini(cv_test['numclaims'], predictions)\n",
    "    gini_scores.append(gini_score)\n",
    "\n",
    "# Calculate the average Gini coefficient\n",
    "average_gini = np.mean(gini_scores)\n",
    "print(f\"Average Gini Coefficient from Cross-Validation: {average_gini}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Gini Coefficient from Cross-Validation: 0.2860533099866334\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Gini Coefficient from Cross-Validation: {average_gini}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept               -2.279430\n",
      "area[T.B]               -0.030603\n",
      "area[T.C]               -0.003049\n",
      "area[T.D]               -0.158172\n",
      "area[T.E]               -0.145635\n",
      "area[T.F]                0.031815\n",
      "gender[T.M]             -0.078984\n",
      "exposure                 1.564745\n",
      "agecat                  -0.086688\n",
      "veh_value                0.009627\n",
      "veh_age                  0.010251\n",
      "driving_history_score    0.001758\n",
      "max_power                0.000023\n",
      "credit_score            -0.001424\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def bootstrap_model(data, model_formula, family, R=500):\n",
    "    boot_coefs = []\n",
    "\n",
    "    for _ in range(R):\n",
    "        boot_sample = data.sample(frac=1, replace=True, random_state=random.randint(1, 10000))\n",
    "        boot_model = glm(model_formula, data=boot_sample, family=family).fit()\n",
    "        boot_coefs.append(boot_model.params)\n",
    "\n",
    "    # Convert list of coefficients to DataFrame\n",
    "    boot_coefs_df = pd.DataFrame(boot_coefs)\n",
    "\n",
    "    # Calculate the average coefficients\n",
    "    avg_coefs = boot_coefs_df.mean(axis=0)\n",
    "    return avg_coefs\n",
    "\n",
    "# Apply bootstrapping\n",
    "avg_boot_coefs = bootstrap_model(train_data, formula, sm.families.Poisson(), R=500)\n",
    "print(avg_boot_coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\3911342461.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output.rename(columns={'predicted_claimcst0': 'Predict'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the vh data\n",
    "vh_data = pd.read_csv('InsNova_data_2023_vh.csv/InsNova_data_2023_vh.csv')\n",
    "# Compute Frequency and Severity predictions\n",
    "# (Replace `frequency_model` and `severity_model` with your actual model objects)\n",
    "vh_data['predicted_frequency'] = frequency_model.predict(vh_data)\n",
    "vh_data['predicted_severity'] = severity_model.predict(vh_data)\n",
    "\n",
    "# Calculate the final claim cost predictions\n",
    "vh_data['predicted_claimcst0'] = vh_data['predicted_frequency'] * vh_data['predicted_severity']\n",
    "# Prepare the output DataFrame\n",
    "output = vh_data[['id', 'predicted_claimcst0']]\n",
    "output.rename(columns={'predicted_claimcst0': 'Predict'}, inplace=True)\n",
    "# Export to CSV\n",
    "output.to_csv('final_predictions2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryane\\AppData\\Local\\Temp\\ipykernel_14984\\1527340432.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output[output['Predict'] <0]['Predict']=0\n"
     ]
    }
   ],
   "source": [
    "output[output['Predict'] <0]['Predict']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning 0 to negative values of Predict\n",
    "output.loc[output['Predict'] < 0, 'Predict'] = 0\n",
    "output.to_csv('final_predictions2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
